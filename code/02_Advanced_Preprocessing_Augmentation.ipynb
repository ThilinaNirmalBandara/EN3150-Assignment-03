{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5434e3e",
   "metadata": {},
   "source": [
    "# Class-Specific Data Augmentation\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This script addresses class imbalance in the training dataset by generating synthetic samples for underrepresented classes. Instead of augmenting the entire dataset, it only creates additional samples for minority classes to match the size of the majority class.\n",
    "\n",
    "## Why This Is Needed\n",
    "\n",
    "Real-world datasets often have class imbalance. For example, you might have:\n",
    "- Cardboard: 500 images\n",
    "- Glass: 300 images  \n",
    "- Metal: 150 images\n",
    "\n",
    "Training on imbalanced data causes the model to bias toward majority classes. This script generates augmented samples for minority classes (glass and metal in this example) to create a balanced training set.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Script Does\n",
    "\n",
    "The script performs five main steps:\n",
    "\n",
    "1. **Loads the training data** - Reads the manifest files created by the EDA script\n",
    "2. **Analyzes class imbalance** - Counts samples per class and identifies which classes need augmentation\n",
    "3. **Defines augmentation strategy** - Sets up various transformations (rotation, flipping, color changes)\n",
    "4. **Generates synthetic samples** - Creates augmented images for minority classes only\n",
    "5. **Saves augmented data** - Exports the new samples as numpy arrays\n",
    "\n",
    "---\n",
    "\n",
    "## Augmentation Techniques Used\n",
    "\n",
    "The script applies random combinations of:\n",
    "\n",
    "- **Geometric transformations**:\n",
    "  - Random cropping (224x224 from 256x256)\n",
    "  - Horizontal flipping (50% chance)\n",
    "  - Vertical flipping (50% chance)\n",
    "  - Rotation (±30 degrees)\n",
    "  - Translation (±10% in x and y)\n",
    "  - Scaling (90-110%)\n",
    "  - Perspective distortion (20% scale, 30% chance)\n",
    "\n",
    "- **Color transformations**:\n",
    "  - Brightness adjustment (±30%)\n",
    "  - Contrast adjustment (±30%)\n",
    "  - Saturation adjustment (±20%)\n",
    "  - Hue adjustment (±10%)\n",
    "\n",
    "Each augmented image is a unique variation of an original image from the same class.\n",
    "\n",
    "---\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Key parameters at the top of the script:\n",
    "\n",
    "```python\n",
    "RANDOM_SEED = 42      # For reproducibility\n",
    "IMAGE_SIZE = 256      # Output image size\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Output Files\n",
    "\n",
    "### Generated Files\n",
    "\n",
    "- **augmented_train_images.npy** - Numpy array containing augmented images\n",
    "  - Shape: (N, 256, 256, 3) where N = number of augmented samples\n",
    "  - Data type: uint8 (0-255 RGB values)\n",
    "  \n",
    "- **augmented_train_labels.npy** - Numpy array with corresponding class labels\n",
    "  - Shape: (N,) \n",
    "  - Contains string labels matching the augmented images\n",
    "\n",
    "### Console Output\n",
    "\n",
    "The script prints:\n",
    "- Original class distribution\n",
    "- Target count (size of largest class)\n",
    "- Number of augmented samples needed per class\n",
    "- Progress bars during generation\n",
    "- Final balanced distribution\n",
    "- Memory usage statistics\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works\n",
    "\n",
    "### Example Scenario\n",
    "\n",
    "Original training distribution:\n",
    "```\n",
    "cardboard: 500 samples\n",
    "glass:     300 samples  \n",
    "metal:     150 samples\n",
    "```\n",
    "\n",
    "The script will:\n",
    "1. Identify target count = 500 (maximum)\n",
    "2. Calculate needed augmentations:\n",
    "   - cardboard: 0 (already at target)\n",
    "   - glass: 200 (500 - 300)\n",
    "   - metal: 350 (500 - 150)\n",
    "3. Randomly select source images from each minority class\n",
    "4. Apply random augmentations to create 550 total new images\n",
    "5. Save only these augmented samples\n",
    "\n",
    "### Augmentation Process\n",
    "\n",
    "For each needed sample:\n",
    "1. Randomly pick an existing image from that class\n",
    "2. Load and convert to RGB\n",
    "3. Apply the augmentation pipeline\n",
    "4. Store the result as a numpy array\n",
    "\n",
    "This ensures diversity while maintaining class characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run\n",
    "\n",
    "```bash\n",
    "python augmentation_notebook.py\n",
    "```\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run the EDA script first to generate manifest files\n",
    "- Required files:\n",
    "  - train_manifest.csv\n",
    "  - val_manifest.csv\n",
    "  - test_manifest.csv\n",
    "  - classes.json\n",
    "\n",
    "**Runtime:** 5-20 minutes depending on augmentation needs\n",
    "\n",
    "---\n",
    "\n",
    "## Memory Considerations\n",
    "\n",
    "The script loads all augmented images into memory before saving. For large augmentation needs:\n",
    "\n",
    "- 1000 images at 256x256x3: ~190 MB\n",
    "- 5000 images at 256x256x3: ~950 MB\n",
    "- 10000 images at 256x256x3: ~1.9 GB\n",
    "\n",
    "If you encounter memory errors, consider:\n",
    "- Reducing IMAGE_SIZE\n",
    "- Processing in batches\n",
    "- Using online augmentation during training instead\n",
    "\n",
    "---\n",
    "\n",
    "## Integration with Training\n",
    "\n",
    "After running this script, the next notebook should:\n",
    "\n",
    "1. Load original training images\n",
    "2. Load augmented images from this script\n",
    "3. Combine both datasets\n",
    "4. Encode labels\n",
    "5. Export final training arrays\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Load original\n",
    "original_images = load_from_manifests(train_df)\n",
    "original_labels = train_df['label'].values\n",
    "\n",
    "# Load augmented\n",
    "aug_images = np.load('augmented_train_images.npy')\n",
    "aug_labels = np.load('augmented_train_labels.npy')\n",
    "\n",
    "# Combine\n",
    "all_images = np.concatenate([original_images, aug_images])\n",
    "all_labels = np.concatenate([original_labels, aug_labels])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "### This Script Only Augments Training Data\n",
    "\n",
    "Validation and test sets are NOT augmented because:\n",
    "- They need to represent real-world distribution\n",
    "- Augmentation would artificially inflate performance metrics\n",
    "- Model evaluation must be on genuine unseen data\n",
    "\n",
    "### Already Balanced Datasets\n",
    "\n",
    "If your dataset is already balanced (all classes have similar counts), the script will:\n",
    "- Detect this automatically\n",
    "- Skip augmentation generation\n",
    "- Report that no augmentation is needed\n",
    "- Exit without creating files\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "Setting RANDOM_SEED ensures:\n",
    "- Same augmentations each run\n",
    "- Consistent results across experiments\n",
    "- Reproducible experiments for your report\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of This Approach\n",
    "\n",
    "**Compared to oversampling:**\n",
    "- Creates diverse variations instead of exact duplicates\n",
    "- Helps model generalize better\n",
    "- Reduces overfitting risk\n",
    "\n",
    "**Compared to undersampling:**\n",
    "- Doesn't discard valuable majority class samples\n",
    "- Uses all available information\n",
    "- Better for small datasets\n",
    "\n",
    "**Compared to augmenting everything:**\n",
    "- More efficient (only augments what's needed)\n",
    "- Faster processing\n",
    "- Less storage required\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d95dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASS-SPECIFIC AUGMENTATION FOR IMBALANCED DATA\n",
      "======================================================================\n",
      "\n",
      "[1/5] Loading training data...\n",
      "✓ Train: 3326 images\n",
      "✓ Val:   713 images\n",
      "✓ Test:  713 images\n",
      "\n",
      "[2/5] Analyzing class distribution...\n",
      "\n",
      "Original class distribution (TRAIN only):\n",
      "  Cardboard           :  323 samples\n",
      "  Food Organics       :  288 samples\n",
      "  Glass               :  294 samples\n",
      "  Metal               :  553 samples\n",
      "  Miscellaneous Trash :  346 samples\n",
      "  Paper               :  350 samples\n",
      "  Plastic             :  645 samples\n",
      "  Textile Trash       :  222 samples\n",
      "  Vegetation          :  305 samples\n",
      "\n",
      "✓ Target count per class: 645\n",
      "  Cardboard           : needs 322 augmented samples\n",
      "  Food Organics       : needs 357 augmented samples\n",
      "  Glass               : needs 351 augmented samples\n",
      "  Metal               : needs 92 augmented samples\n",
      "  Miscellaneous Trash : needs 299 augmented samples\n",
      "  Paper               : needs 295 augmented samples\n",
      "  Textile Trash       : needs 423 augmented samples\n",
      "  Vegetation          : needs 340 augmented samples\n",
      "\n",
      "[3/5] Defining augmentation strategy...\n",
      "✓ Augmentation strategy defined\n",
      "\n",
      "[4/5] Generating augmented samples...\n",
      "Total augmented samples to generate: 2479\n",
      "\n",
      "Processing Cardboard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Cardboard: 100%|██████████| 322/322 [00:04<00:00, 78.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Food Organics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Food Organics: 100%|██████████| 357/357 [00:05<00:00, 70.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Glass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Glass: 100%|██████████| 351/351 [00:04<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Metal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Metal: 100%|██████████| 92/92 [00:01<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Miscellaneous Trash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Miscellaneous Trash: 100%|██████████| 299/299 [00:04<00:00, 69.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Paper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Paper: 100%|██████████| 295/295 [00:04<00:00, 69.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Textile Trash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Textile Trash: 100%|██████████| 423/423 [00:06<00:00, 69.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Vegetation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Vegetation: 100%|██████████| 340/340 [00:05<00:00, 64.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Generated 2479 augmented images\n",
      "  Shape: (2479, 256, 256, 3)\n",
      "  Memory: 464.8 MB\n",
      "\n",
      "[5/5] Saving augmented data...\n",
      "✓ Saved files:\n",
      "  - augmented_train_images.npy\n",
      "  - augmented_train_labels.npy\n",
      "\n",
      "======================================================================\n",
      "AUGMENTATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Class distribution after augmentation:\n",
      "  Cardboard           :  323 (original) +  322 (augmented) =  645 (total)\n",
      "  Food Organics       :  288 (original) +  357 (augmented) =  645 (total)\n",
      "  Glass               :  294 (original) +  351 (augmented) =  645 (total)\n",
      "  Metal               :  553 (original) +   92 (augmented) =  645 (total)\n",
      "  Miscellaneous Trash :  346 (original) +  299 (augmented) =  645 (total)\n",
      "  Paper               :  350 (original) +  295 (augmented) =  645 (total)\n",
      "  Plastic             :  645 (original) +    0 (augmented) =  645 (total)\n",
      "  Textile Trash       :  222 (original) +  423 (augmented) =  645 (total)\n",
      "  Vegetation          :  305 (original) +  340 (augmented) =  645 (total)\n",
      "\n",
      "Total training samples: 3326 → 5805\n",
      "\n",
      "Next step: Run Notebook 03 to combine and export to final NPY format\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook 02: Class-Specific Augmentation for Imbalanced Data\n",
    "=============================================================\n",
    "Generates synthetic samples for minority classes ONLY\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ==========================================\n",
    "# 0) Configuration\n",
    "# ==========================================\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_SIZE = 256\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLASS-SPECIFIC AUGMENTATION FOR IMBALANCED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==========================================\n",
    "# 1) Load Training Data\n",
    "# ==========================================\n",
    "print(\"\\n[1/5] Loading training data...\")\n",
    "\n",
    "train_df = pd.read_csv(\"train_manifest.csv\")\n",
    "val_df = pd.read_csv(\"val_manifest.csv\")\n",
    "test_df = pd.read_csv(\"test_manifest.csv\")\n",
    "\n",
    "with open(\"classes.json\") as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "print(f\"✓ Train: {len(train_df)} images\")\n",
    "print(f\"✓ Val:   {len(val_df)} images\")\n",
    "print(f\"✓ Test:  {len(test_df)} images\")\n",
    "\n",
    "# ==========================================\n",
    "# 2) Analyze Class Imbalance\n",
    "# ==========================================\n",
    "print(\"\\n[2/5] Analyzing class distribution...\")\n",
    "\n",
    "class_counts = train_df['label'].value_counts()\n",
    "print(\"\\nOriginal class distribution (TRAIN only):\")\n",
    "for cls in class_names:\n",
    "    count = class_counts.get(cls, 0)\n",
    "    print(f\"  {cls:20s}: {count:4d} samples\")\n",
    "\n",
    "# Determine target count\n",
    "target_count = class_counts.max()\n",
    "print(f\"\\n✓ Target count per class: {target_count}\")\n",
    "\n",
    "# Calculate needed augmentations\n",
    "augmentation_needed = {}\n",
    "for cls in class_names:\n",
    "    current = class_counts.get(cls, 0)\n",
    "    needed = max(0, target_count - current)\n",
    "    augmentation_needed[cls] = needed\n",
    "    if needed > 0:\n",
    "        print(f\"  {cls:20s}: needs {needed} augmented samples\")\n",
    "\n",
    "# ==========================================\n",
    "# 3) Define Augmentation Transform\n",
    "# ==========================================\n",
    "print(\"\\n[3/5] Defining augmentation strategy...\")\n",
    "\n",
    "augment_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.RandomCrop(224),\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize back\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "])\n",
    "\n",
    "print(\"✓ Augmentation strategy defined\")\n",
    "\n",
    "# ==========================================\n",
    "# 4) Generate Augmented Samples\n",
    "# ==========================================\n",
    "print(\"\\n[4/5] Generating augmented samples...\")\n",
    "\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "total_to_generate = sum(augmentation_needed.values())\n",
    "print(f\"Total augmented samples to generate: {total_to_generate}\")\n",
    "\n",
    "if total_to_generate == 0:\n",
    "    print(\"\\n⚠ Dataset is already balanced! No augmentation needed.\")\n",
    "else:\n",
    "    for class_name in class_names:\n",
    "        needed = augmentation_needed[class_name]\n",
    "        \n",
    "        if needed == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing {class_name}...\")\n",
    "        \n",
    "        # Get all images from this class\n",
    "        class_df = train_df[train_df['label'] == class_name]\n",
    "        class_paths = class_df['path'].values\n",
    "        \n",
    "        # Generate augmented samples\n",
    "        for i in tqdm(range(needed), desc=f\"Augmenting {class_name}\"):\n",
    "            # Randomly select a source image\n",
    "            source_path = np.random.choice(class_paths)\n",
    "            \n",
    "            # Load image\n",
    "            img = Image.open(source_path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Apply augmentation\n",
    "            aug_img = augment_transform(img_array)\n",
    "            aug_array = np.array(aug_img, dtype=np.uint8)\n",
    "            \n",
    "            # Store\n",
    "            augmented_images.append(aug_array)\n",
    "            augmented_labels.append(class_name)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    augmented_images = np.array(augmented_images)\n",
    "    augmented_labels = np.array(augmented_labels)\n",
    "    \n",
    "    print(f\"\\n✓ Generated {len(augmented_images)} augmented images\")\n",
    "    print(f\"  Shape: {augmented_images.shape}\")\n",
    "    print(f\"  Memory: {augmented_images.nbytes / (1024**2):.1f} MB\")\n",
    "\n",
    "# ==========================================\n",
    "# 5) Save Augmented Data\n",
    "# ==========================================\n",
    "print(\"\\n[5/5] Saving augmented data...\")\n",
    "\n",
    "if total_to_generate > 0:\n",
    "    np.save(\"augmented_train_images.npy\", augmented_images)\n",
    "    np.save(\"augmented_train_labels.npy\", augmented_labels)\n",
    "    \n",
    "    print(\"✓ Saved files:\")\n",
    "    print(\"  - augmented_train_images.npy\")\n",
    "    print(\"  - augmented_train_labels.npy\")\n",
    "else:\n",
    "    print(\"✓ No augmented data to save (dataset already balanced)\")\n",
    "\n",
    "# ==========================================\n",
    "# Summary\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AUGMENTATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nClass distribution after augmentation:\")\n",
    "for cls in class_names:\n",
    "    original = class_counts.get(cls, 0)\n",
    "    augmented = augmentation_needed[cls]\n",
    "    total = original + augmented\n",
    "    print(f\"  {cls:20s}: {original:4d} (original) + {augmented:4d} (augmented) = {total:4d} (total)\")\n",
    "\n",
    "print(f\"\\nTotal training samples: {len(train_df)} → {len(train_df) + total_to_generate}\")\n",
    "\n",
    "print(\"\\nNext step: Run Notebook 03 to combine and export to final NPY format\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
