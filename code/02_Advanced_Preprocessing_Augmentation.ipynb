{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d95dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASS-SPECIFIC AUGMENTATION FOR IMBALANCED DATA\n",
      "======================================================================\n",
      "\n",
      "[1/5] Loading training data...\n",
      "✓ Train: 3326 images\n",
      "✓ Val:   713 images\n",
      "✓ Test:  713 images\n",
      "\n",
      "[2/5] Analyzing class distribution...\n",
      "\n",
      "Original class distribution (TRAIN only):\n",
      "  Cardboard           :  323 samples\n",
      "  Food Organics       :  288 samples\n",
      "  Glass               :  294 samples\n",
      "  Metal               :  553 samples\n",
      "  Miscellaneous Trash :  346 samples\n",
      "  Paper               :  350 samples\n",
      "  Plastic             :  645 samples\n",
      "  Textile Trash       :  222 samples\n",
      "  Vegetation          :  305 samples\n",
      "\n",
      "✓ Target count per class: 645\n",
      "  Cardboard           : needs 322 augmented samples\n",
      "  Food Organics       : needs 357 augmented samples\n",
      "  Glass               : needs 351 augmented samples\n",
      "  Metal               : needs 92 augmented samples\n",
      "  Miscellaneous Trash : needs 299 augmented samples\n",
      "  Paper               : needs 295 augmented samples\n",
      "  Textile Trash       : needs 423 augmented samples\n",
      "  Vegetation          : needs 340 augmented samples\n",
      "\n",
      "[3/5] Defining augmentation strategy...\n",
      "✓ Augmentation strategy defined\n",
      "\n",
      "[4/5] Generating augmented samples...\n",
      "Total augmented samples to generate: 2479\n",
      "\n",
      "Processing Cardboard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Cardboard: 100%|██████████| 322/322 [00:04<00:00, 78.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Food Organics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Food Organics: 100%|██████████| 357/357 [00:05<00:00, 70.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Glass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Glass: 100%|██████████| 351/351 [00:04<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Metal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Metal: 100%|██████████| 92/92 [00:01<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Miscellaneous Trash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Miscellaneous Trash: 100%|██████████| 299/299 [00:04<00:00, 69.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Paper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Paper: 100%|██████████| 295/295 [00:04<00:00, 69.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Textile Trash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Textile Trash: 100%|██████████| 423/423 [00:06<00:00, 69.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Vegetation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Vegetation: 100%|██████████| 340/340 [00:05<00:00, 64.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Generated 2479 augmented images\n",
      "  Shape: (2479, 256, 256, 3)\n",
      "  Memory: 464.8 MB\n",
      "\n",
      "[5/5] Saving augmented data...\n",
      "✓ Saved files:\n",
      "  - augmented_train_images.npy\n",
      "  - augmented_train_labels.npy\n",
      "\n",
      "======================================================================\n",
      "AUGMENTATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Class distribution after augmentation:\n",
      "  Cardboard           :  323 (original) +  322 (augmented) =  645 (total)\n",
      "  Food Organics       :  288 (original) +  357 (augmented) =  645 (total)\n",
      "  Glass               :  294 (original) +  351 (augmented) =  645 (total)\n",
      "  Metal               :  553 (original) +   92 (augmented) =  645 (total)\n",
      "  Miscellaneous Trash :  346 (original) +  299 (augmented) =  645 (total)\n",
      "  Paper               :  350 (original) +  295 (augmented) =  645 (total)\n",
      "  Plastic             :  645 (original) +    0 (augmented) =  645 (total)\n",
      "  Textile Trash       :  222 (original) +  423 (augmented) =  645 (total)\n",
      "  Vegetation          :  305 (original) +  340 (augmented) =  645 (total)\n",
      "\n",
      "Total training samples: 3326 → 5805\n",
      "\n",
      "Next step: Run Notebook 03 to combine and export to final NPY format\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook 02: Class-Specific Augmentation for Imbalanced Data\n",
    "=============================================================\n",
    "Generates synthetic samples for minority classes ONLY\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ==========================================\n",
    "# 0) Configuration\n",
    "# ==========================================\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_SIZE = 256\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLASS-SPECIFIC AUGMENTATION FOR IMBALANCED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==========================================\n",
    "# 1) Load Training Data\n",
    "# ==========================================\n",
    "print(\"\\n[1/5] Loading training data...\")\n",
    "\n",
    "train_df = pd.read_csv(\"train_manifest.csv\")\n",
    "val_df = pd.read_csv(\"val_manifest.csv\")\n",
    "test_df = pd.read_csv(\"test_manifest.csv\")\n",
    "\n",
    "with open(\"classes.json\") as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "print(f\"✓ Train: {len(train_df)} images\")\n",
    "print(f\"✓ Val:   {len(val_df)} images\")\n",
    "print(f\"✓ Test:  {len(test_df)} images\")\n",
    "\n",
    "# ==========================================\n",
    "# 2) Analyze Class Imbalance\n",
    "# ==========================================\n",
    "print(\"\\n[2/5] Analyzing class distribution...\")\n",
    "\n",
    "class_counts = train_df['label'].value_counts()\n",
    "print(\"\\nOriginal class distribution (TRAIN only):\")\n",
    "for cls in class_names:\n",
    "    count = class_counts.get(cls, 0)\n",
    "    print(f\"  {cls:20s}: {count:4d} samples\")\n",
    "\n",
    "# Determine target count\n",
    "target_count = class_counts.max()\n",
    "print(f\"\\n✓ Target count per class: {target_count}\")\n",
    "\n",
    "# Calculate needed augmentations\n",
    "augmentation_needed = {}\n",
    "for cls in class_names:\n",
    "    current = class_counts.get(cls, 0)\n",
    "    needed = max(0, target_count - current)\n",
    "    augmentation_needed[cls] = needed\n",
    "    if needed > 0:\n",
    "        print(f\"  {cls:20s}: needs {needed} augmented samples\")\n",
    "\n",
    "# ==========================================\n",
    "# 3) Define Augmentation Transform\n",
    "# ==========================================\n",
    "print(\"\\n[3/5] Defining augmentation strategy...\")\n",
    "\n",
    "augment_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.RandomCrop(224),\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize back\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "])\n",
    "\n",
    "print(\"✓ Augmentation strategy defined\")\n",
    "\n",
    "# ==========================================\n",
    "# 4) Generate Augmented Samples\n",
    "# ==========================================\n",
    "print(\"\\n[4/5] Generating augmented samples...\")\n",
    "\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "total_to_generate = sum(augmentation_needed.values())\n",
    "print(f\"Total augmented samples to generate: {total_to_generate}\")\n",
    "\n",
    "if total_to_generate == 0:\n",
    "    print(\"\\n⚠ Dataset is already balanced! No augmentation needed.\")\n",
    "else:\n",
    "    for class_name in class_names:\n",
    "        needed = augmentation_needed[class_name]\n",
    "        \n",
    "        if needed == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing {class_name}...\")\n",
    "        \n",
    "        # Get all images from this class\n",
    "        class_df = train_df[train_df['label'] == class_name]\n",
    "        class_paths = class_df['path'].values\n",
    "        \n",
    "        # Generate augmented samples\n",
    "        for i in tqdm(range(needed), desc=f\"Augmenting {class_name}\"):\n",
    "            # Randomly select a source image\n",
    "            source_path = np.random.choice(class_paths)\n",
    "            \n",
    "            # Load image\n",
    "            img = Image.open(source_path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Apply augmentation\n",
    "            aug_img = augment_transform(img_array)\n",
    "            aug_array = np.array(aug_img, dtype=np.uint8)\n",
    "            \n",
    "            # Store\n",
    "            augmented_images.append(aug_array)\n",
    "            augmented_labels.append(class_name)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    augmented_images = np.array(augmented_images)\n",
    "    augmented_labels = np.array(augmented_labels)\n",
    "    \n",
    "    print(f\"\\n✓ Generated {len(augmented_images)} augmented images\")\n",
    "    print(f\"  Shape: {augmented_images.shape}\")\n",
    "    print(f\"  Memory: {augmented_images.nbytes / (1024**2):.1f} MB\")\n",
    "\n",
    "# ==========================================\n",
    "# 5) Save Augmented Data\n",
    "# ==========================================\n",
    "print(\"\\n[5/5] Saving augmented data...\")\n",
    "\n",
    "if total_to_generate > 0:\n",
    "    np.save(\"augmented_train_images.npy\", augmented_images)\n",
    "    np.save(\"augmented_train_labels.npy\", augmented_labels)\n",
    "    \n",
    "    print(\"✓ Saved files:\")\n",
    "    print(\"  - augmented_train_images.npy\")\n",
    "    print(\"  - augmented_train_labels.npy\")\n",
    "else:\n",
    "    print(\"✓ No augmented data to save (dataset already balanced)\")\n",
    "\n",
    "# ==========================================\n",
    "# Summary\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AUGMENTATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nClass distribution after augmentation:\")\n",
    "for cls in class_names:\n",
    "    original = class_counts.get(cls, 0)\n",
    "    augmented = augmentation_needed[cls]\n",
    "    total = original + augmented\n",
    "    print(f\"  {cls:20s}: {original:4d} (original) + {augmented:4d} (augmented) = {total:4d} (total)\")\n",
    "\n",
    "print(f\"\\nTotal training samples: {len(train_df)} → {len(train_df) + total_to_generate}\")\n",
    "\n",
    "print(\"\\nNext step: Run Notebook 03 to combine and export to final NPY format\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
