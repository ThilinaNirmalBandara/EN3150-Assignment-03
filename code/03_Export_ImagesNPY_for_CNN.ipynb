{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1438cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPORTING BALANCED DATASET TO NPY FORMAT\n",
      "======================================================================\n",
      "\n",
      "Target image size: 256×256\n",
      "\n",
      "[1/5] Loading original split information...\n",
      "✓ Original data:\n",
      "  Total: 4752\n",
      "  Train: 3326\n",
      "  Val: 713\n",
      "  Test: 713\n",
      "\n",
      "[2/5] Loading augmented data...\n",
      "✓ Loaded 2479 augmented images\n",
      "\n",
      "[3/5] Loading and resizing ORIGINAL images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original images: 100%|██████████| 4752/4752 [00:25<00:00, 184.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Original images shape: (4752, 256, 256, 3)\n",
      "\n",
      "[4/5] Creating balanced training split...\n",
      "✓ Combined dataset:\n",
      "  Original train: 3326 images\n",
      "  Augmented: 2479 images\n",
      "  Total train: 5805 images\n",
      "  Val: 713 images\n",
      "  Test: 713 images\n",
      "  Total: 7231 images\n",
      "\n",
      "[5/5] Saving final NPY files...\n",
      "✓ Saved files:\n",
      "  - images.npy (all images including augmented)\n",
      "  - labels.npy (all labels)\n",
      "  - split_train.npy (train indices - includes augmented)\n",
      "  - split_val.npy\n",
      "  - split_test.npy\n",
      "  - class_names.npy\n",
      "  - filepaths.npy\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "✓ Balanced class distribution:\n",
      "\n",
      "Class                   Train      Val     Test\n",
      "------------------------------------------------------------\n",
      "Cardboard                 645       69       69\n",
      "Food Organics             645       61       62\n",
      "Glass                     645       63       63\n",
      "Metal                     645      119      118\n",
      "Miscellaneous Trash       645       74       75\n",
      "Paper                     645       75       75\n",
      "Plastic                   645      138      138\n",
      "Textile Trash             645       48       48\n",
      "Vegetation                645       66       65\n",
      "------------------------------------------------------------\n",
      "TOTAL                    5805      713      713\n",
      "\n",
      "✓ Dataset is now balanced and ready for training!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook 03: Export Combined (Original + Augmented) Images to NPY\n",
    "==================================================================\n",
    "Combines original images with augmented minority class samples\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPORTING BALANCED DATASET TO NPY FORMAT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==========================================\n",
    "# 0) Configuration\n",
    "# ==========================================\n",
    "FINAL_SIZE = (256, 256)\n",
    "print(f\"\\nTarget image size: {FINAL_SIZE[0]}×{FINAL_SIZE[1]}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1) Load Original Split Information\n",
    "# ==========================================\n",
    "print(\"\\n[1/5] Loading original split information...\")\n",
    "\n",
    "train_df = pd.read_csv(\"train_manifest.csv\")\n",
    "val_df = pd.read_csv(\"val_manifest.csv\")\n",
    "test_df = pd.read_csv(\"test_manifest.csv\")\n",
    "df = pd.read_csv(\"manifest_clean.csv\")\n",
    "\n",
    "with open(\"classes.json\") as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "print(f\"✓ Original data:\")\n",
    "print(f\"  Total: {len(df)}\")\n",
    "print(f\"  Train: {len(train_df)}\")\n",
    "print(f\"  Val: {len(val_df)}\")\n",
    "print(f\"  Test: {len(test_df)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2) Load Augmented Data (if exists)\n",
    "# ==========================================\n",
    "print(\"\\n[2/5] Loading augmented data...\")\n",
    "\n",
    "has_augmented = os.path.exists(\"augmented_train_images.npy\")\n",
    "\n",
    "if has_augmented:\n",
    "    augmented_images = np.load(\"augmented_train_images.npy\")\n",
    "    augmented_labels = np.load(\"augmented_train_labels.npy\", allow_pickle=True)\n",
    "    print(f\"✓ Loaded {len(augmented_images)} augmented images\")\n",
    "else:\n",
    "    augmented_images = np.array([])\n",
    "    augmented_labels = np.array([])\n",
    "    print(\"⚠ No augmented data found - using original data only\")\n",
    "\n",
    "# ==========================================\n",
    "# 3) Load and Resize Original Images\n",
    "# ==========================================\n",
    "print(\"\\n[3/5] Loading and resizing ORIGINAL images...\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(class_names)\n",
    "\n",
    "paths = df[\"path\"].values\n",
    "labels_encoded = le.transform(df[\"label\"].values)\n",
    "original_images = []\n",
    "\n",
    "for path in tqdm(paths, desc=\"Processing original images\"):\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img_resized = img.resize(FINAL_SIZE, resample=Image.BILINEAR)\n",
    "        img_array = np.array(img_resized, dtype=np.uint8)\n",
    "        original_images.append(img_array)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠ Error loading {path}: {e}\")\n",
    "        original_images.append(np.zeros((FINAL_SIZE[0], FINAL_SIZE[1], 3), dtype=np.uint8))\n",
    "\n",
    "original_images = np.stack(original_images, axis=0)\n",
    "print(f\"✓ Original images shape: {original_images.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4) Create Balanced Training Split\n",
    "# ==========================================\n",
    "print(\"\\n[4/5] Creating balanced training split...\")\n",
    "\n",
    "# Create index mapping\n",
    "path_to_idx = {path: idx for idx, path in enumerate(df[\"path\"].values)}\n",
    "\n",
    "# Original train indices\n",
    "train_indices_original = np.array([path_to_idx[path] for path in train_df[\"path\"].values])\n",
    "\n",
    "# Val and test indices (unchanged)\n",
    "val_indices = np.array([path_to_idx[path] for path in val_df[\"path\"].values])\n",
    "test_indices = np.array([path_to_idx[path] for path in test_df[\"path\"].values])\n",
    "\n",
    "if has_augmented:\n",
    "    # Combine original images with augmented ones\n",
    "    all_images = np.concatenate([original_images, augmented_images], axis=0)\n",
    "    \n",
    "    # Encode augmented labels\n",
    "    augmented_labels_encoded = le.transform(augmented_labels)\n",
    "    all_labels = np.concatenate([labels_encoded, augmented_labels_encoded], axis=0)\n",
    "    \n",
    "    # Train indices = original train + new augmented indices\n",
    "    augmented_start_idx = len(original_images)\n",
    "    augmented_indices = np.arange(augmented_start_idx, augmented_start_idx + len(augmented_images))\n",
    "    train_indices = np.concatenate([train_indices_original, augmented_indices])\n",
    "    \n",
    "    print(f\"✓ Combined dataset:\")\n",
    "    print(f\"  Original train: {len(train_indices_original)} images\")\n",
    "    print(f\"  Augmented: {len(augmented_images)} images\")\n",
    "    print(f\"  Total train: {len(train_indices)} images\")\n",
    "else:\n",
    "    all_images = original_images\n",
    "    all_labels = labels_encoded\n",
    "    train_indices = train_indices_original\n",
    "    print(f\"✓ Using original data only (no augmentation)\")\n",
    "\n",
    "print(f\"  Val: {len(val_indices)} images\")\n",
    "print(f\"  Test: {len(test_indices)} images\")\n",
    "print(f\"  Total: {len(all_images)} images\")\n",
    "\n",
    "# ==========================================\n",
    "# 5) Save Everything\n",
    "# ==========================================\n",
    "print(\"\\n[5/5] Saving final NPY files...\")\n",
    "\n",
    "np.save(\"images.npy\", all_images)\n",
    "np.save(\"labels.npy\", all_labels.astype(np.int64))\n",
    "np.save(\"split_train.npy\", train_indices)\n",
    "np.save(\"split_val.npy\", val_indices)\n",
    "np.save(\"split_test.npy\", test_indices)\n",
    "np.save(\"class_names.npy\", np.array(class_names))\n",
    "np.save(\"filepaths.npy\", paths)\n",
    "\n",
    "print(\"✓ Saved files:\")\n",
    "print(\"  - images.npy (all images including augmented)\")\n",
    "print(\"  - labels.npy (all labels)\")\n",
    "print(\"  - split_train.npy (train indices - includes augmented)\")\n",
    "print(\"  - split_val.npy\")\n",
    "print(\"  - split_test.npy\")\n",
    "print(\"  - class_names.npy\")\n",
    "print(\"  - filepaths.npy\")\n",
    "\n",
    "# ==========================================\n",
    "# 6) Verification\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_labels = all_labels[train_indices]\n",
    "val_labels = all_labels[val_indices]\n",
    "test_labels = all_labels[test_indices]\n",
    "\n",
    "print(\"\\n✓ Balanced class distribution:\")\n",
    "print(f\"\\n{'Class':<20} {'Train':>8} {'Val':>8} {'Test':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, cls in enumerate(class_names):\n",
    "    train_count = np.sum(train_labels == i)\n",
    "    val_count = np.sum(val_labels == i)\n",
    "    test_count = np.sum(test_labels == i)\n",
    "    print(f\"{cls:<20} {train_count:>8} {val_count:>8} {test_count:>8}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'TOTAL':<20} {len(train_indices):>8} {len(val_indices):>8} {len(test_indices):>8}\")\n",
    "\n",
    "print(\"\\n✓ Dataset is now balanced and ready for training!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
